#!/usr/bin/env python3
"""
AIæœåŠ¡æ¨¡å— - æ”¯æŒè±†åŒ…(Doubao)æ¨¡å‹é›†æˆ
æä¾›å›¾ç‰‡ç†è§£ã€æ–‡æœ¬ç”Ÿæˆç­‰åŠŸèƒ½ï¼ŒåŒ…å«è‡ªåŠ¨æ•…éšœè½¬ç§»æœºåˆ¶
"""

import os
import json
import asyncio
import aiohttp
from typing import Dict, List, Any, Optional, Union
from abc import ABC, abstractmethod
from datetime import datetime
import logging
from dataclasses import dataclass
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AIModelConfig:
    """AIæ¨¡å‹é…ç½®"""
    name: str
    base_url: str
    api_key: str
    model_id: str
    max_tokens: int = 4000
    temperature: float = 0.7

class BaseAIProvider(ABC):
    """AIæœåŠ¡æä¾›å•†åŸºç±»"""
    
    def __init__(self, config: AIModelConfig):
        self.config = config
        self.session = None
    
    async def __aenter__(self):
        # é…ç½®SSLè®¾ç½®ï¼Œè·³è¿‡è¯ä¹¦éªŒè¯ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
        connector = aiohttp.TCPConnector(ssl=False)
        self.session = aiohttp.ClientSession(connector=connector)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    @abstractmethod
    async def analyze_image(self, image_url: str, prompt: str) -> str:
        """åˆ†æå›¾ç‰‡å†…å®¹"""
        pass
    
    @abstractmethod
    async def generate_text(self, prompt: str, context: str = "") -> str:
        """ç”Ÿæˆæ–‡æœ¬å†…å®¹"""
        pass
    
    @abstractmethod
    async def optimize_text(self, text: str, style: str = "professional") -> str:
        """ä¼˜åŒ–æ–‡æœ¬å†…å®¹"""
        pass

class DoubaoProvider(BaseAIProvider):
    """è±†åŒ…AIæœåŠ¡æä¾›å•†"""
    
    def __init__(self, config: AIModelConfig, is_backup: bool = False):
        super().__init__(config)
        self.is_backup = is_backup
        self.provider_name = "è±†åŒ…å¤‡ç”¨æ–¹æ¡ˆ" if is_backup else "è±†åŒ…ä¸»æ–¹æ¡ˆ"
    
    async def _make_request(self, messages: List[Dict], model_override: str = None) -> str:
        """å‘é€APIè¯·æ±‚"""
        if not self.session:
            raise RuntimeError("Session not initialized. Use async context manager.")
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.api_key}"
        }
        
        data = {
            "model": model_override or self.config.model_id,
            "messages": messages,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature
        }
        
        try:
            logger.info(f"[{self.provider_name}] å‘é€è¯·æ±‚åˆ°: {self.config.base_url}")
            logger.debug(f"[{self.provider_name}] è¯·æ±‚æ•°æ®: {json.dumps(data, ensure_ascii=False, indent=2)}")
            
            async with self.session.post(
                f"{self.config.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=aiohttp.ClientTimeout(total=120)  # å¢åŠ è¶…æ—¶æ—¶é—´
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    content = result["choices"][0]["message"]["content"]
                    logger.info(f"[{self.provider_name}] è¯·æ±‚æˆåŠŸ")
                    return content
                else:
                    error_text = await response.text()
                    logger.error(f"[{self.provider_name}] APIé”™è¯¯ {response.status}: {error_text}")
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                    
        except Exception as e:
            logger.error(f"[{self.provider_name}] è¯·æ±‚å¼‚å¸¸: {str(e)}")
            raise
    
    async def analyze_image(self, image_url: str, prompt: str) -> str:
        """åˆ†æå›¾ç‰‡å†…å®¹"""
        # æ ¹æ®æ˜¯å¦ä¸ºå¤‡ç”¨æ–¹æ¡ˆé€‰æ‹©ä¸åŒçš„æ¨¡å‹
        model = "doubao-1-5-thinking-vision-pro-250428" if self.is_backup else "doubao-vision-pro-32k-241028"
        
        messages = [{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": prompt
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": image_url
                    }
                }
            ]
        }]
        
        return await self._make_request(messages, model)
    
    async def generate_text(self, prompt: str, context: str = "") -> str:
        """ç”Ÿæˆæ–‡æœ¬å†…å®¹"""
        # æ ¹æ®æ˜¯å¦ä¸ºå¤‡ç”¨æ–¹æ¡ˆé€‰æ‹©ä¸åŒçš„æ¨¡å‹
        model = "doubao-seed-1-6-thinking-250615" if self.is_backup else "doubao-seed-1-6-250615"
        
        full_prompt = f"{context}\n\n{prompt}" if context else prompt
        
        messages = [{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": full_prompt
                }
            ]
        }]
        
        return await self._make_request(messages, model)
    
    async def optimize_text(self, text: str, style: str = "professional") -> str:
        """ä¼˜åŒ–æ–‡æœ¬å†…å®¹"""
        # å¤‡ç”¨æ–¹æ¡ˆä½¿ç”¨thinkingæ¨¡å‹è¿›è¡Œæ–‡æœ¬ä¼˜åŒ–
        model = "doubao-seed-1-6-thinking-250615" if self.is_backup else "doubao-seed-1-6-250615"
        
        style_prompts = {
            "professional": "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ä¼˜åŒ–ä¸ºä¸“ä¸šã€æ­£å¼çš„è¡¨è¾¾æ–¹å¼",
            "literary": "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ä¼˜åŒ–ä¸ºæ–‡å­¦æ€§ã€å¯Œæœ‰æ„Ÿæƒ…è‰²å½©çš„è¡¨è¾¾æ–¹å¼", 
            "storytelling": "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ä¼˜åŒ–ä¸ºç”ŸåŠ¨ã€å¼•äººå…¥èƒœçš„æ•…äº‹å™è¿°æ–¹å¼",
            "warm": "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ä¼˜åŒ–ä¸ºæ¸©é¦¨ã€äº²åˆ‡çš„è¡¨è¾¾æ–¹å¼"
        }
        
        prompt = f"{style_prompts.get(style, style_prompts['professional'])}ï¼Œä¿æŒåŸæ„ä¸å˜ï¼Œä½¿è¡¨è¾¾æ›´åŠ ä¼˜ç¾æµç•…ï¼š\n\n{text}"
        
        messages = [{
            "role": "user", 
            "content": [
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }]
        
        return await self._make_request(messages, model)

class AIService:
    """AIæœåŠ¡ç®¡ç†å™¨ - æ”¯æŒä¸»å¤‡æ–¹æ¡ˆè‡ªåŠ¨åˆ‡æ¢"""
    
    def __init__(self):
        # ä¸»æ–¹æ¡ˆé…ç½®
        self.primary_config = AIModelConfig(
            name="è±†åŒ…ä¸»æ–¹æ¡ˆ",
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=os.getenv("DOUBAO_API_KEY", ""),
            model_id="doubao-vision-pro-32k-241028",
            max_tokens=4000,
            temperature=0.7
        )
        
        # å¤‡ç”¨æ–¹æ¡ˆé…ç½®
        self.backup_config = AIModelConfig(
            name="è±†åŒ…å¤‡ç”¨æ–¹æ¡ˆ",
            base_url="https://ark.cn-beijing.volces.com/api/v3", 
            api_key=os.getenv("DOUBAO_API_KEY", ""),
            model_id="doubao-1-5-thinking-vision-pro-250428",
            max_tokens=4000,
            temperature=0.7
        )
        
        self.failure_count = 0
        self.max_failures = 3  # æœ€å¤§å¤±è´¥æ¬¡æ•°ï¼Œè¶…è¿‡ååˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ
        self.using_backup = False
    
    async def _execute_with_fallback(self, operation: str, *args, **kwargs):
        """æ‰§è¡Œæ“ä½œï¼Œæ”¯æŒè‡ªåŠ¨æ•…éšœè½¬ç§»"""
        
        # é¦–å…ˆå°è¯•ä¸»æ–¹æ¡ˆï¼ˆé™¤éå·²ç»åˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆï¼‰
        if not self.using_backup:
            try:
                async with DoubaoProvider(self.primary_config, is_backup=False) as provider:
                    if operation == "analyze_image":
                        result = await provider.analyze_image(*args, **kwargs)
                    elif operation == "generate_text":
                        result = await provider.generate_text(*args, **kwargs)
                    elif operation == "optimize_text":
                        result = await provider.optimize_text(*args, **kwargs)
                    else:
                        raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œ: {operation}")
                    
                    # æˆåŠŸæ—¶é‡ç½®å¤±è´¥è®¡æ•°
                    self.failure_count = 0
                    logger.info(f"âœ… ä¸»æ–¹æ¡ˆæˆåŠŸæ‰§è¡Œ {operation}")
                    return result
                    
            except Exception as e:
                self.failure_count += 1
                logger.warning(f"âš ï¸ ä¸»æ–¹æ¡ˆå¤±è´¥ ({self.failure_count}/{self.max_failures}): {str(e)}")
                
                # å¦‚æœå¤±è´¥æ¬¡æ•°è¶…è¿‡é˜ˆå€¼ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ
                if self.failure_count >= self.max_failures:
                    self.using_backup = True
                    logger.warning(f"ğŸ”„ åˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ")
        
        # ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        try:
            async with DoubaoProvider(self.backup_config, is_backup=True) as provider:
                if operation == "analyze_image":
                    result = await provider.analyze_image(*args, **kwargs)
                elif operation == "generate_text":
                    result = await provider.generate_text(*args, **kwargs)
                elif operation == "optimize_text":
                    result = await provider.optimize_text(*args, **kwargs)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œ: {operation}")
                
                logger.info(f"âœ… å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸæ‰§è¡Œ {operation}")
                return result
                
        except Exception as e:
            logger.error(f"âŒ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥äº†: {str(e)}")
            raise Exception(f"ä¸»å¤‡æ–¹æ¡ˆéƒ½å¤±è´¥äº†ã€‚ä¸»æ–¹æ¡ˆé”™è¯¯æ¬¡æ•°: {self.failure_count}, å¤‡ç”¨æ–¹æ¡ˆé”™è¯¯: {str(e)}")
    
    async def analyze_image(self, image_url: str, prompt: str = "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€åœºæ™¯ã€æ´»åŠ¨ã€æƒ…ç»ªç­‰ç»†èŠ‚") -> str:
        """åˆ†æå›¾ç‰‡å†…å®¹"""
        return await self._execute_with_fallback("analyze_image", image_url, prompt)
    
    async def generate_text(self, prompt: str, context: str = "") -> str:
        """ç”Ÿæˆæ–‡æœ¬å†…å®¹ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
        return await self._execute_with_fallback("generate_text", prompt, context)
    
    async def generate_biography_text(self, image_analyses: List[str], user_requirements: str = "", style: str = "warm") -> str:
        """ç”Ÿæˆä¼ è®°æ–‡æœ¬"""
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        print(f"ğŸ¤– AIæœåŠ¡æ”¶åˆ°ä¼ è®°ç”Ÿæˆè¯·æ±‚:")
        print(f"ğŸ“Š ç”¨æˆ·éœ€æ±‚é•¿åº¦: {len(user_requirements)} å­—ç¬¦")
        print(f"ğŸ“ ç”¨æˆ·éœ€æ±‚å†…å®¹é¢„è§ˆ: {user_requirements[:500]}...")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”¨æˆ·çœŸå®ä¿¡æ¯
        if "ç”Ÿæ´»ç‰‡æ®µ" in user_requirements:
            print("âœ… å‘ç°ç”¨æˆ·çœŸå®ä¿¡æ¯ç‰‡æ®µ")
        else:
            print("âŒ æœªå‘ç°ç”¨æˆ·çœŸå®ä¿¡æ¯ç‰‡æ®µ")
            
        if "Early Years" in user_requirements or "School Days" in user_requirements:
            print("âš ï¸ éœ€æ±‚ä¸­åŒ…å«é€šç”¨ç« èŠ‚ï¼Œè¿™ä¸åº”è¯¥å‡ºç°")
        
        # è¶…å¼ºåŒ–æç¤ºè¯ - ä½¿ç”¨æ›´ä¸¥æ ¼çš„æŒ‡ä»¤
        prompt = f"""
ğŸš¨ CRITICAL INSTRUCTION: You MUST strictly follow these rules. Violation of ANY rule means COMPLETE FAILURE ğŸš¨

ç”¨æˆ·çš„çœŸå®ä¿¡æ¯ï¼š
{user_requirements if user_requirements else "è¯·å†™ä¸€ç¯‡ä¸ªäººä¼ è®°"}

å›¾ç‰‡å‚è€ƒä¿¡æ¯ï¼š
{chr(10).join([f"{i+1}. {analysis}" for i, analysis in enumerate(image_analyses)])}

âŒâŒâŒ ABSOLUTELY FORBIDDEN CONTENT (INSTANT FAILURE IF USED) âŒâŒâŒ
- "Early Years" / "ç«¥å¹´æ—¶å…‰" / "æ—©å¹´æ—¶æœŸ" / "å¹¼å¹´æ—¶ä»£"  
- "School Days" / "å­¦ç”Ÿæ—¶ä»£" / "æ±‚å­¦æ—¶å…‰" / "æ ¡å›­ç”Ÿæ´»"
- "Family Time" / "å®¶åº­æ—¶å…‰" / "å®¶åº­ç”Ÿæ´»" / "å®¶äººé™ªä¼´"  
- "Growing Up" / "æˆé•¿å†ç¨‹" / "é’æ˜¥å²æœˆ" / "æˆé•¿æ—¶å…‰"
- "Childhood" / "Youth" / "Education" / "Career"
- ANY fabricated childhood stories, school experiences, family descriptions
- ANY content not explicitly provided by the user

âœ…âœ…âœ… MANDATORY REQUIREMENTS (ALL MUST BE FOLLOWED) âœ…âœ…âœ…
1. ã€ONLY USER'S REAL INFOã€‘: Base EVERYTHING on user's provided information
2. ã€PERSONALIZED TITLESã€‘: Chapter titles MUST reflect user's specific periods (e.g., "2020å¹´å¤å¤©çš„æ—¶å…‰", "è¥¿è—ä¹‹æ—…çš„å›å¿†")  
3. ã€NO FABRICATIONã€‘: Do NOT add any people, places, events not mentioned by user
4. ã€USER-DRIVEN CHAPTERSã€‘: Each chapter corresponds to ONE user-provided life segment
5. ã€AUTHENTIC CONTENTã€‘: If information is insufficient, write brief authentic content rather than fabricate

=== STRICT WRITING FRAMEWORK ===
- å¼€ç¯‡: Brief introduction based ONLY on user's provided info (max 1 paragraph)
- ä¸»ä½“ç« èŠ‚: Each chapter = One user's real life segment with personalized title
- ç»“å°¾: Brief conclusion based ONLY on user's real experiences (max 1 paragraph)

=== CONTENT VALIDATION ===
Before generating, ask yourself:
- Does this contain ANY forbidden terms? â†’ If YES, REWRITE
- Is every sentence based on user's real info? â†’ If NO, REMOVE  
- Are chapter titles personalized? â†’ If NO, CHANGE
- Am I fabricating anything? â†’ If YES, STOP and use only real info

=== OUTPUT REQUIREMENTS ===
- è¯­è¨€: ä¸­æ–‡
- å­—æ•°: 800-1200å­—
- è¯­è°ƒ: æ¸©é¦¨çœŸå®ï¼ŒåŸºäºç”¨æˆ·çœŸå®ç»å†
- ç»“æ„: å®Œå…¨ä¸ªæ€§åŒ–ï¼Œç»æ— é€šç”¨æ¨¡æ¿

ğŸ”¥ FINAL WARNING: If you generate "Early Years", "School Days" or any forbidden content, this is a COMPLETE FAILURE. 
SUCCESS = 100% personalized content based ONLY on user's real information.

ç°åœ¨è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚åˆ›ä½œä¼ è®°ï¼š
        """
        
        print(f"ğŸ“ æœ€ç»ˆæç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        result = await self._execute_with_fallback("generate_text", prompt)
        
        # æ£€æŸ¥ç”Ÿæˆç»“æœè´¨é‡
        print(f"ğŸ“– ç”Ÿæˆç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
        
        # éªŒè¯æ˜¯å¦åŒ…å«ç¦ç”¨è¯æ±‡
        forbidden_terms = ["Early Years", "School Days", "Family Time", "Growing Up", 
                          "ç«¥å¹´æ—¶å…‰", "å­¦ç”Ÿæ—¶ä»£", "å®¶åº­æ—¶å…‰", "æˆé•¿å†ç¨‹"]
        found_forbidden = []
        for term in forbidden_terms:
            if term in result:
                found_forbidden.append(term)
        
        if found_forbidden:
            print(f"âŒ AIä»ç„¶ç”Ÿæˆäº†ç¦ç”¨è¯æ±‡: {found_forbidden}")
        else:
            print("âœ… AIæˆåŠŸé¿å…äº†æ‰€æœ‰ç¦ç”¨è¯æ±‡")
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”¨æˆ·çœŸå®ä¿¡æ¯
        user_info_keywords = []
        if "2020" in result: user_info_keywords.append("2020")
        if "2022" in result: user_info_keywords.append("2022") 
        if "2024" in result: user_info_keywords.append("2024")
        if "è¥¿è—" in result or "Xizang" in result: user_info_keywords.append("è¥¿è—/Xizang")
        
        print(f"âœ… å‘ç°ç”¨æˆ·çœŸå®ä¿¡æ¯: {user_info_keywords}")
        
        return result
    
    async def optimize_text(self, text: str, style: str = "professional") -> str:
        """ä¼˜åŒ–æ–‡æœ¬å†…å®¹"""
        return await self._execute_with_fallback("optimize_text", text, style)
    
    def validate_generated_content(self, content: str, user_requirements: str) -> tuple[bool, list]:
        """éªŒè¯ç”Ÿæˆå†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚"""
        issues = []
        
        # æ£€æŸ¥ç¦ç”¨è¯æ±‡
        forbidden_terms = ["Early Years", "School Days", "Family Time", "Growing Up", 
                          "ç«¥å¹´æ—¶å…‰", "å­¦ç”Ÿæ—¶ä»£", "å®¶åº­æ—¶å…‰", "æˆé•¿å†ç¨‹", "é’æ˜¥å²æœˆ",
                          "å¹¼å¹´æ—¶ä»£", "æ ¡å›­ç”Ÿæ´»", "å®¶äººé™ªä¼´", "æˆé•¿æ—¶å…‰"]
        
        for term in forbidden_terms:
            if term in content:
                issues.append(f"åŒ…å«ç¦ç”¨è¯æ±‡: {term}")
        
        # æ£€æŸ¥ç”¨æˆ·ä¿¡æ¯èå…¥
        if "ç”Ÿæ´»ç‰‡æ®µ" in user_requirements:
            # æå–ç”¨æˆ·æåˆ°çš„æ—¶æœŸ
            time_matches = re.findall(r'æ—¶æœŸï¼š([^\n]+)', user_requirements)
            found_periods = 0
            for time_period in time_matches:
                # æ£€æŸ¥æ—¶æœŸæ˜¯å¦åœ¨å†…å®¹ä¸­è¢«æåŠ
                if time_period in content or any(keyword in content for keyword in time_period.split()):
                    found_periods += 1
            
            if len(time_matches) > 0 and found_periods == 0:
                issues.append("æœªèå…¥ä»»ä½•ç”¨æˆ·æä¾›çš„æ—¶æœŸä¿¡æ¯")
            elif found_periods < len(time_matches) * 0.5:  # è‡³å°‘èå…¥50%çš„æ—¶æœŸä¿¡æ¯
                issues.append(f"ç”¨æˆ·ä¿¡æ¯èå…¥ä¸è¶³: {found_periods}/{len(time_matches)}")
        
        return len(issues) == 0, issues
    
    async def generate_biography_with_validation(self, image_analyses: List[str], user_requirements: str = "", style: str = "warm", max_attempts: int = 3) -> str:
        """å¸¦éªŒè¯çš„ä¼ è®°ç”Ÿæˆï¼Œå¦‚æœå†…å®¹ä¸åˆæ ¼ä¼šè‡ªåŠ¨é‡æ–°ç”Ÿæˆ"""
        original_requirements = user_requirements
        
        for attempt in range(max_attempts):
            print(f"ğŸ”„ ç¬¬{attempt+1}æ¬¡ç”Ÿæˆå°è¯•...")
            
            try:
                content = await self.generate_biography_text(image_analyses, user_requirements, style)
                is_valid, issues = self.validate_generated_content(content, original_requirements)
                
                if is_valid:
                    print("âœ… ç”Ÿæˆå†…å®¹é€šè¿‡éªŒè¯")
                    return content
                else:
                    print(f"âŒ ç”Ÿæˆå†…å®¹ä¸åˆæ ¼: {issues}")
                    if attempt < max_attempts - 1:
                        print("ğŸ”„ å‡†å¤‡é‡æ–°ç”Ÿæˆ...")
                        # åŠ å¼ºæç¤ºè¯ï¼Œæ˜ç¡®æŒ‡å‡ºä¸Šæ¬¡çš„é—®é¢˜
                        user_requirements = original_requirements + f"\n\nâš ï¸ ä¸Šæ¬¡ç”Ÿæˆå¤±è´¥åŸå› : {', '.join(issues)}\nè¯·åŠ¡å¿…é¿å…è¿™äº›é—®é¢˜ï¼ç»å¯¹ä¸è¦ä½¿ç”¨ä»»ä½•é€šç”¨ç« èŠ‚æ ‡é¢˜ï¼"
                    else:
                        print(f"âŒ ç»è¿‡{max_attempts}æ¬¡å°è¯•ä»æ— æ³•ç”Ÿæˆåˆæ ¼å†…å®¹")
                        # å³ä½¿ä¸åˆæ ¼ä¹Ÿè¿”å›æœ€åä¸€æ¬¡çš„ç»“æœï¼Œé¿å…å®Œå…¨å¤±è´¥
                        return content
                        
            except Exception as e:
                print(f"âŒ ç¬¬{attempt+1}æ¬¡ç”Ÿæˆå‡ºç°å¼‚å¸¸: {str(e)}")
                if attempt == max_attempts - 1:
                    raise e
        
        raise Exception(f"ç»è¿‡{max_attempts}æ¬¡å°è¯•ä»æ— æ³•ç”Ÿæˆå†…å®¹")
    
    async def generate_chapter_titles(self, biography_text: str) -> List[str]:
        """ç”Ÿæˆç« èŠ‚æ ‡é¢˜"""
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹ä¼ è®°å†…å®¹ç”Ÿæˆ5-8ä¸ªç« èŠ‚æ ‡é¢˜ï¼Œè¦æ±‚ï¼š
1. æ ‡é¢˜ç®€æ´æœ‰åŠ›ï¼Œå¯Œæœ‰æ„Ÿæƒ…è‰²å½©
2. ä½“ç°äººç”Ÿçš„é‡è¦é˜¶æ®µå’Œè½¬æŠ˜ç‚¹
3. æ¯ä¸ªæ ‡é¢˜ä¸è¶…è¿‡10ä¸ªå­—
4. æŒ‰æ—¶é—´é¡ºåºæ’åˆ—

ä¼ è®°å†…å®¹ï¼š
{biography_text}

è¯·åªè¿”å›ç« èŠ‚æ ‡é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªæ ‡é¢˜ï¼š
        """
        
        result = await self._execute_with_fallback("generate_text", prompt)
        # è§£æç« èŠ‚æ ‡é¢˜
        titles = [line.strip() for line in result.split('\n') if line.strip() and not line.strip().startswith('ç« èŠ‚æ ‡é¢˜')]
        return titles[:8]  # æœ€å¤š8ä¸ªç« èŠ‚
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–AIæœåŠ¡çŠ¶æ€"""
        return {
            "using_backup": self.using_backup,
            "failure_count": self.failure_count,
            "max_failures": self.max_failures,
            "primary_model": self.primary_config.model_id,
            "backup_model": self.backup_config.model_id,
            "current_provider": "è±†åŒ…å¤‡ç”¨æ–¹æ¡ˆ" if self.using_backup else "è±†åŒ…ä¸»æ–¹æ¡ˆ"
        }
    
    def reset_to_primary(self):
        """é‡ç½®ä¸ºä¸»æ–¹æ¡ˆ"""
        self.using_backup = False
        self.failure_count = 0
        logger.info("ğŸ”„ å·²é‡ç½®ä¸ºä¸»æ–¹æ¡ˆ")

# å…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = AIService()

# ä¾¿æ·å‡½æ•°
async def analyze_image(image_url: str, prompt: str = None) -> str:
    """åˆ†æå›¾ç‰‡ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    return await ai_service.analyze_image(image_url, prompt or "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹")

async def generate_biography(image_analyses: List[str], user_requirements: str = "", style: str = "warm") -> str:
    """ç”Ÿæˆä¼ è®°ï¼ˆä¾¿æ·å‡½æ•°ï¼‰- ä½¿ç”¨éªŒè¯æœºåˆ¶"""
    return await ai_service.generate_biography_with_validation(image_analyses, user_requirements, style)

async def optimize_text(text: str, style: str = "professional") -> str:
    """ä¼˜åŒ–æ–‡æœ¬ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    return await ai_service.optimize_text(text, style)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test_ai_service():
        print("ğŸ§ª æµ‹è¯•AIæœåŠ¡...")
        
        # æµ‹è¯•å›¾ç‰‡åˆ†æ
        test_image_url = "https://ark-project.tos-cn-beijing.ivolces.com/images/view.jpeg"
        
        try:
            result = await analyze_image(test_image_url, "è¿™å¼ å›¾ç‰‡ä¸»è¦è®²äº†ä»€ä¹ˆï¼Ÿ")
            print(f"âœ… å›¾ç‰‡åˆ†ææˆåŠŸ: {result[:100]}...")
        except Exception as e:
            print(f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
        
        # æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
        try:
            result = await generate_biography(
                ["ä¸€å¼ æ¸©é¦¨çš„å®¶åº­ç…§ç‰‡"], 
                "è¯·å†™ä¸€ç¯‡å…³äºå®¶åº­æ¸©æš–çš„ä¼ è®°"
            )
            print(f"âœ… ä¼ è®°ç”ŸæˆæˆåŠŸ: {result[:100]}...")
        except Exception as e:
            print(f"âŒ ä¼ è®°ç”Ÿæˆå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºçŠ¶æ€
        status = ai_service.get_status()
        print(f"ğŸ“Š AIæœåŠ¡çŠ¶æ€: {status}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_ai_service()) 